import streamlit as st
from docx import Document
from io import BytesIO
from textblob import TextBlob
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
import requests
import re

# Descargar recursos necesarios para nltk y textblob
nltk.download('punkt')
nltk.download('stopwords')

# Configuraci√≥n del API de LanguageTool
LANGUAGE_TOOL_API_URL = "https://api.languagetool.org/v2/check"

# Funci√≥n para corregir texto usando el API p√∫blico de LanguageTool
def corregir_texto(texto):
    # Separar el texto en partes dentro y fuera de comillas
    partes = separar_citas(texto)
    texto_corregido = ""

    for parte in partes:
        # Si la parte est√° dentro de comillas, no se corrige
        if re.match(r'(\".*?\"|‚Äú.*?‚Äù|‚Äò.*?‚Äô)', parte):
            texto_corregido += parte
        else:
            # Aplicar correcciones al texto fuera de comillas
            try:
                texto_corregido += corregir_segmento(parte)
            except Exception as e:
                st.error(f"Error al corregir el texto: {e}")
                texto_corregido += parte  # Mantener el texto original en caso de error

    return texto_corregido

# Funci√≥n para corregir un segmento de texto usando el API de LanguageTool
def corregir_segmento(texto):
    payload = {
        'text': texto,
        'language': 'es',
        'enabledOnly': False,
        'removeDuplicates': 'true'
    }

    response = requests.post(LANGUAGE_TOOL_API_URL, data=payload)

    if response.status_code != 200:
        raise Exception(f"Error en la API de LanguageTool: {response.status_code} - {response.text}")

    resultado = response.json()

    matches = resultado.get('matches', [])

    # Aplicar correcciones de atr√°s hacia adelante para no alterar los √≠ndices
    texto_modificado = texto
    offset_correction = 0  # Correcci√≥n acumulada de los offsets debido a cambios en el texto

    for match in sorted(matches, key=lambda x: x['offset']):
        offset = match['offset'] + offset_correction
        length = match['length']
        replacements = match.get('replacements', [])

        if not replacements:
            continue  # No hay sugerencias de correcci√≥n

        replacement = replacements[0]['value']

        # Reemplazar el texto en el rango especificado
        texto_modificado = (
            texto_modificado[:offset] +
            replacement +
            texto_modificado[offset + length:]
        )

        # Actualizar la correcci√≥n acumulada
        offset_correction += len(replacement) - length

    # Correcci√≥n de acentos con TextBlob
    blob = TextBlob(texto_modificado)
    texto_corregido_final = str(blob.correct())

    # Correcci√≥n de capitalizaci√≥n
    texto_corregido_final = capitalizar_primer_caracter(texto_corregido_final)

    # Eliminaci√≥n de repeticiones de palabras
    texto_corregido_final = eliminar_repeticiones(texto_corregido_final)

    return texto_corregido_final

# Funci√≥n para eliminar repeticiones de palabras
def eliminar_repeticiones(texto):
    palabras = word_tokenize(texto, language='spanish')
    stop_words = set(stopwords.words('spanish'))
    palabras_filtradas = []
    palabras_vistas = set()
    for palabra in palabras:
        palabra_lower = palabra.lower()
        if palabra_lower not in palabras_vistas or palabra_lower in stop_words:
            palabras_filtradas.append(palabra)
            palabras_vistas.add(palabra_lower)
    texto_corregido = ' '.join(palabras_filtradas)
    return texto_corregido

# Funci√≥n para separar texto dentro y fuera de comillas
def separar_citas(texto):
    # Expresi√≥n regular para encontrar textos entre comillas simples o dobles
    pattern = r'(\".*?\"|‚Äú.*?‚Äù|‚Äò.*?‚Äô)'
    partes = re.split(pattern, texto)
    return partes

# Funci√≥n para capitalizar la primera letra de un texto
def capitalizar_primer_caracter(texto):
    if not texto:
        return texto
    return texto[0].upper() + texto[1:]

# Funci√≥n principal para procesar el documento .docx
def procesar_documento(doc_bytes):
    # Cargar el documento
    documento = Document(BytesIO(doc_bytes))
    
    # Iterar sobre cada p√°rrafo y aplicar las correcciones
    for para in documento.paragraphs:
        texto_original = para.text
        if texto_original.strip() == '':
            continue  # Salta p√°rrafos vac√≠os
        
        # Corregir el texto del p√°rrafo
        texto_corregido = corregir_texto(texto_original)
        
        # Reemplazar el texto del p√°rrafo con el texto corregido
        para.text = texto_corregido
    
    # Guardar el documento corregido en un objeto BytesIO
    corrected_doc = BytesIO()
    documento.save(corrected_doc)
    corrected_doc.seek(0)
    
    return corrected_doc

# Funci√≥n para dividir textos largos en p√°rrafos usando NLTK
def dividir_en_parrafos(texto, max_sentencias=5):
    # Tokenizar el texto en oraciones
    oraciones = sent_tokenize(texto, language='spanish')
    parrafos = []
    parrafo_actual = []

    for oracion in oraciones:
        parrafo_actual.append(oracion)
        if len(parrafo_actual) >= max_sentencias:
            parrafos.append(' '.join(parrafo_actual))
            parrafo_actual = []
    
    # A√±adir el √∫ltimo p√°rrafo si tiene oraciones
    if parrafo_actual:
        parrafos.append(' '.join(parrafo_actual))
    
    return parrafos

# Interfaz de usuario con Streamlit
def main():
    st.set_page_config(page_title="Corrector y Divisor de Textos en Espa√±ol", layout="wide")
    st.title("Corrector y Divisor de Textos en Espa√±ol")
    st.write("""
        Esta aplicaci√≥n permite:
        1. **Corregir documentos `.docx`**: Errores ortogr√°ficos, acentos, capitalizaci√≥n, repeticiones de palabras y puntuaci√≥n.
        2. **Dividir textos largos en p√°rrafos**: Utilizando procesamiento de lenguaje natural para una divisi√≥n l√≥gica.
    """)
    
    # Crear pesta√±as para separar funcionalidades
    pesta√±as = st.tabs(["üîß Corregir Documento `.docx`", "‚úÇÔ∏è Dividir Texto en P√°rrafos"])
    
    # Pesta√±a 1: Corregir Documento `.docx`
    with pesta√±as[0]:
        st.header("Corregir Documento `.docx`")
        st.write("Sube un archivo `.docx` para corregir errores ortogr√°ficos, acentos, capitalizaci√≥n, repeticiones de palabras y puntuaci√≥n. **Las citas textuales y las notas a pie de p√°gina no ser√°n corregidas.**")
        
        uploaded_file = st.file_uploader("Elige un archivo `.docx`", type="docx")
        
        if uploaded_file is not None:
            st.success("Archivo cargado exitosamente.")
            
            # Procesar el documento al hacer clic en el bot√≥n
            if st.button("Corregir Documento"):
                with st.spinner("Procesando el documento..."):
                    try:
                        corrected_doc = procesar_documento(uploaded_file.read())
                        st.success("Documento corregido exitosamente.")
                        
                        # Permitir al usuario descargar el archivo corregido
                        st.download_button(
                            label="Descargar Documento Corregido",
                            data=corrected_doc,
                            file_name="documento_corregido.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                    except Exception as e:
                        st.error(f"Error al procesar el documento: {e}")

    # Pesta√±a 2: Dividir Texto en P√°rrafos
    with pesta√±as[1]:
        st.header("Dividir Texto en P√°rrafos")
        st.write("Puedes cargar un archivo de texto `.txt` o pegar texto largo en el cuadro de texto a continuaci√≥n para dividirlo en p√°rrafos.")
        
        # Opciones para cargar un archivo o pegar texto
        opciones = ["Cargar Archivo `.txt`", "Pegar Texto"]
        seleccion = st.radio("Selecciona una opci√≥n:", opciones)
        
        texto_procesar = ""
        
        if seleccion == "Cargar Archivo `.txt`":
            uploaded_txt = st.file_uploader("Elige un archivo `.txt`", type="txt")
            if uploaded_txt is not None:
                bytes_data = uploaded_txt.read()
                try:
                    texto_procesar = bytes_data.decode('utf-8')
                    st.success("Archivo de texto cargado exitosamente.")
                except UnicodeDecodeError:
                    st.error("Error al decodificar el archivo. Aseg√∫rate de que est√© en formato UTF-8.")
        
        elif seleccion == "Pegar Texto":
            texto_procesar = st.text_area("Pega tu texto aqu√≠:", height=300)
        
        if texto_procesar:
            if st.button("Dividir en P√°rrafos"):
                with st.spinner("Dividiendo el texto en p√°rrafos..."):
                    try:
                        parrafos = dividir_en_parrafos(texto_procesar)
                        st.success("Texto dividido en p√°rrafos exitosamente.")
                        
                        st.write("### P√°rrafos Resultantes:")
                        for idx, parrafo in enumerate(parrafos, 1):
                            st.write(f"**P√°rrafo {idx}:** {parrafo}")
                    except Exception as e:
                        st.error(f"Error al dividir el texto: {e}")

if __name__ == "__main__":
    main()
